{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b1e6244d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import import_ipynb\n",
    "import NeuralNet_FromScratch as nnfs_module\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import style\n",
    "from nnfs.datasets import spiral_data\n",
    "from nnfs.datasets import sine_data\n",
    "from zipfile import ZipFile\n",
    "import nnfs\n",
    "import os\n",
    "import urllib\n",
    "import urllib.request\n",
    "import cv2\n",
    "\n",
    "style.use(\"dark_background\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afef6b27",
   "metadata": {},
   "source": [
    "# Retreive Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07050469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date preparation is complete.\n"
     ]
    }
   ],
   "source": [
    "URL = 'https://nnfs.io/datasets/fashion_mnist_images.zip'\n",
    "FILE = 'fashion_mnist_images.zip'\n",
    "FOLDER = 'fashion_mnist_images'\n",
    "\n",
    "if not os.path.isfile(FILE):\n",
    "    print(f'Downloading {URL} and saving as {FILE}...')\n",
    "    urllib.request.urlretrieve(URL, FILE)\n",
    "\n",
    "if not os.path.isdir(FOLDER):\n",
    "    print(\"Unzipping images ...\")\n",
    "    with ZipFile(FILE) as zip_images:\n",
    "        zip_images.extractall(FOLDER)\n",
    "    print('DONE')\n",
    "    \n",
    "print(\"Date preparation is complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079414a9",
   "metadata": {},
   "source": [
    "# Fashion MNIST Classifications\n",
    "0: T-shirt / top\n",
    "\n",
    "1: Trouser\n",
    "\n",
    "2: Pullover\n",
    "\n",
    "3: Dress\n",
    "\n",
    "4: Coat\n",
    "\n",
    "5: Sandal\n",
    "\n",
    "6: Shirt\n",
    "\n",
    "7: Sneaker\n",
    "\n",
    "8: Bag\n",
    "\n",
    "9: Ankle Boot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df978819",
   "metadata": {},
   "source": [
    "# Data Loading Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fe8920",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mnist_dataset(dataset, path):\n",
    "    \n",
    "    #scan all directories and create list of labels\n",
    "    labels = os.listdir(os.path.join(path, dataset))\n",
    "    \n",
    "    #create lists for samples and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    #for each label folder\n",
    "    for label in labels:\n",
    "        #for each image in the given folder\n",
    "        for file in os.listdir(os.path.join(path, dataset, label)):\n",
    "            #read the image\n",
    "            image = cv2.imread(os.path.join(\\\n",
    "                                path, dataset, label, file),\\\n",
    "                               cv2.IMREAD_UNCHANGED)\n",
    "            \n",
    "            #append image to x and label to y\n",
    "            X.append(image)\n",
    "            y.append(label)\n",
    "            \n",
    "    #convert data structure to numpy arrays and return\n",
    "    return np.array(X), np.array(y).astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abccd25",
   "metadata": {},
   "source": [
    "# Create MNIST Train & Test Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfa603b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_mnist(path):\n",
    "    \n",
    "    #load both sets\n",
    "    X, y = load_mnist_dataset('train', path)\n",
    "    X_test, y_test = load_mnist_dataset('test', path)\n",
    "    \n",
    "    #return all datasets\n",
    "    return X, y, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bd8149",
   "metadata": {},
   "source": [
    "# Generate Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f079590f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "60000\n",
      "10000\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "X, y, X_test, y_test = create_data_mnist(FOLDER)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "print(len(X_test))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c3d4f",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79039775",
   "metadata": {},
   "source": [
    "## Scale features\n",
    "range from -1 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7224c820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0 1.0\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "X = (X.astype(np.float32) - 127.5) / 127.5\n",
    "X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "print(X.min(), X.max())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e413d27",
   "metadata": {},
   "source": [
    "## Reshape Data\n",
    "From 3D to 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6b998c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "X = X.reshape(X.shape[0], -1)\n",
    "X_test = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "print(X.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0485d225",
   "metadata": {},
   "source": [
    "## Shuffle Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47b56be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "keys = np.array(range(X.shape[0])) #number of indices in samples\n",
    "np.random.shuffle(keys) #shuffle indices\n",
    "\n",
    "#grab by indice and assign to array\n",
    "X = X[keys]\n",
    "y = y[keys]\n",
    "\n",
    "#test shuffling\n",
    "plt.imshow(X[8].reshape(28,28), cmap='gray') #reshape back to a matrix for veiwing\n",
    "plt.show()\n",
    "print(y[8])\n",
    "\n",
    "plt.imshow(X[999].reshape(28,28), cmap='gray') #reshape back to a matrix for veiwing\n",
    "plt.show()\n",
    "print(y[999])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e7e9f0",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b092134c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 0, acc: 0.172, loss: 2.468 (data_loss: 2.468, reg_loss: 0.000000), lr: 0.001\n",
      "step: 100, acc: 0.742, loss: 0.599 (data_loss: 0.599, reg_loss: 0.000000), lr: 0.0009950248756218907\n",
      "step: 200, acc: 0.898, loss: 0.357 (data_loss: 0.357, reg_loss: 0.000000), lr: 0.0009900990099009901\n",
      "step: 300, acc: 0.836, loss: 0.473 (data_loss: 0.473, reg_loss: 0.000000), lr: 0.0009852216748768474\n",
      "step: 400, acc: 0.844, loss: 0.475 (data_loss: 0.475, reg_loss: 0.000000), lr: 0.000980392156862745\n",
      "step: 468, acc: 0.875, loss: 0.372 (data_loss: 0.372, reg_loss: 0.000000), lr: 0.0009771350400625367\n",
      "epoch: 2\n",
      "step: 0, acc: 0.836, loss: 0.505 (data_loss: 0.505, reg_loss: 0.000000), lr: 0.0009770873027505008\n",
      "step: 100, acc: 0.828, loss: 0.484 (data_loss: 0.484, reg_loss: 0.000000), lr: 0.000972337012008362\n",
      "step: 200, acc: 0.938, loss: 0.245 (data_loss: 0.245, reg_loss: 0.000000), lr: 0.0009676326866321544\n",
      "step: 300, acc: 0.883, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000000), lr: 0.0009629736626703259\n",
      "step: 400, acc: 0.867, loss: 0.435 (data_loss: 0.435, reg_loss: 0.000000), lr: 0.0009583592888974076\n",
      "step: 468, acc: 0.906, loss: 0.316 (data_loss: 0.316, reg_loss: 0.000000), lr: 0.0009552466924583273\n",
      "epoch: 3\n",
      "step: 0, acc: 0.867, loss: 0.421 (data_loss: 0.421, reg_loss: 0.000000), lr: 0.0009552010698251983\n",
      "step: 100, acc: 0.836, loss: 0.459 (data_loss: 0.459, reg_loss: 0.000000), lr: 0.0009506607091928891\n",
      "step: 200, acc: 0.922, loss: 0.205 (data_loss: 0.205, reg_loss: 0.000000), lr: 0.0009461633077869241\n",
      "step: 300, acc: 0.891, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000000), lr: 0.0009417082587814295\n",
      "step: 400, acc: 0.883, loss: 0.391 (data_loss: 0.391, reg_loss: 0.000000), lr: 0.0009372949667260287\n",
      "step: 468, acc: 0.927, loss: 0.277 (data_loss: 0.277, reg_loss: 0.000000), lr: 0.000934317481080071\n",
      "epoch: 4\n",
      "step: 0, acc: 0.859, loss: 0.393 (data_loss: 0.393, reg_loss: 0.000000), lr: 0.0009342738356612324\n",
      "step: 100, acc: 0.844, loss: 0.429 (data_loss: 0.429, reg_loss: 0.000000), lr: 0.0009299297903008323\n",
      "step: 200, acc: 0.914, loss: 0.192 (data_loss: 0.192, reg_loss: 0.000000), lr: 0.0009256259545517657\n",
      "step: 300, acc: 0.875, loss: 0.319 (data_loss: 0.319, reg_loss: 0.000000), lr: 0.0009213617727000506\n",
      "step: 400, acc: 0.883, loss: 0.355 (data_loss: 0.355, reg_loss: 0.000000), lr: 0.0009171366992250195\n",
      "step: 468, acc: 0.906, loss: 0.252 (data_loss: 0.252, reg_loss: 0.000000), lr: 0.0009142857142857143\n",
      "epoch: 5\n",
      "step: 0, acc: 0.875, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000000), lr: 0.0009142439202779302\n",
      "step: 100, acc: 0.836, loss: 0.419 (data_loss: 0.419, reg_loss: 0.000000), lr: 0.0009100837277029487\n",
      "step: 200, acc: 0.922, loss: 0.178 (data_loss: 0.178, reg_loss: 0.000000), lr: 0.0009059612248595759\n",
      "step: 300, acc: 0.891, loss: 0.291 (data_loss: 0.291, reg_loss: 0.000000), lr: 0.0009018759018759019\n",
      "step: 400, acc: 0.891, loss: 0.329 (data_loss: 0.329, reg_loss: 0.000000), lr: 0.0008978272580355541\n",
      "step: 468, acc: 0.906, loss: 0.236 (data_loss: 0.236, reg_loss: 0.000000), lr: 0.0008950948800572861\n",
      "training, acc: 0.886, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000000), lr: 0.0008950948800572861\n",
      "Validation, acc: 0.873, loss: 0.360\n"
     ]
    }
   ],
   "source": [
    "#instantiate the model\n",
    "model = nnfs_module.Model()\n",
    "\n",
    "#add layers\n",
    "model.add(nnfs_module.Layer_Dense(X.shape[1], 64)) #dense layer 1 with 64 neurons\n",
    "model.add(nnfs_module.ReLU_Activation()) #ReLU used for activation\n",
    "model.add(nnfs_module.Layer_Dense(64,64)) #dense layer 2 with 64 neurons\n",
    "model.add(nnfs_module.ReLU_Activation())\n",
    "model.add(nnfs_module.Layer_Dense(64,10)) #dense layer 3 with 10 neurons\n",
    "model.add(nnfs_module.Activation_Softmax()) #output layer using Softmax for categorical classification\n",
    "\n",
    "#set loss, optimizer and accuracy objects\n",
    "model.set(\\\n",
    "         loss=nnfs_module.Loss_CategoricalCrossEntropy(),\\\n",
    "         optimizer=nnfs_module.Optimizer_Adam(decay=5e-5),\\\n",
    "         accuracy=nnfs_module.Accuracy_Categorical())\n",
    "\n",
    "#finalize the model\n",
    "model.finalize()\n",
    "\n",
    "#train the model\n",
    "model.train(X, y, validation_data=(X_test, y_test),\\\n",
    "           epochs=5, batch_size=128, print_every=100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6815108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 0, acc: 0.133, loss: 2.664 (data_loss: 2.664, reg_loss: 0.000000), lr: 0.001\n",
      "step: 100, acc: 0.766, loss: 0.571 (data_loss: 0.571, reg_loss: 0.000000), lr: 0.0009090909090909091\n",
      "step: 200, acc: 0.891, loss: 0.330 (data_loss: 0.330, reg_loss: 0.000000), lr: 0.0008333333333333334\n",
      "step: 300, acc: 0.844, loss: 0.413 (data_loss: 0.413, reg_loss: 0.000000), lr: 0.0007692307692307692\n",
      "step: 400, acc: 0.883, loss: 0.436 (data_loss: 0.436, reg_loss: 0.000000), lr: 0.0007142857142857143\n",
      "step: 468, acc: 0.885, loss: 0.354 (data_loss: 0.354, reg_loss: 0.000000), lr: 0.000681198910081744\n",
      "epoch: 2\n",
      "step: 0, acc: 0.852, loss: 0.478 (data_loss: 0.478, reg_loss: 0.000000), lr: 0.0006807351940095304\n",
      "step: 100, acc: 0.820, loss: 0.480 (data_loss: 0.480, reg_loss: 0.000000), lr: 0.0006373486297004461\n",
      "step: 200, acc: 0.930, loss: 0.244 (data_loss: 0.244, reg_loss: 0.000000), lr: 0.0005991611743559018\n",
      "step: 300, acc: 0.875, loss: 0.297 (data_loss: 0.297, reg_loss: 0.000000), lr: 0.0005652911249293386\n",
      "step: 400, acc: 0.867, loss: 0.370 (data_loss: 0.370, reg_loss: 0.000000), lr: 0.0005350454788657037\n",
      "step: 468, acc: 0.917, loss: 0.296 (data_loss: 0.296, reg_loss: 0.000000), lr: 0.0005162622612287042\n",
      "epoch: 3\n",
      "step: 0, acc: 0.867, loss: 0.415 (data_loss: 0.415, reg_loss: 0.000000), lr: 0.0005159958720330237\n",
      "step: 100, acc: 0.852, loss: 0.428 (data_loss: 0.428, reg_loss: 0.000000), lr: 0.0004906771344455348\n",
      "step: 200, acc: 0.930, loss: 0.207 (data_loss: 0.207, reg_loss: 0.000000), lr: 0.0004677268475210477\n",
      "step: 300, acc: 0.898, loss: 0.257 (data_loss: 0.257, reg_loss: 0.000000), lr: 0.00044682752457551384\n",
      "step: 400, acc: 0.883, loss: 0.340 (data_loss: 0.340, reg_loss: 0.000000), lr: 0.00042771599657827206\n",
      "step: 468, acc: 0.927, loss: 0.255 (data_loss: 0.255, reg_loss: 0.000000), lr: 0.0004156275976724854\n",
      "epoch: 4\n",
      "step: 0, acc: 0.867, loss: 0.389 (data_loss: 0.389, reg_loss: 0.000000), lr: 0.0004154549231408392\n",
      "step: 100, acc: 0.852, loss: 0.403 (data_loss: 0.403, reg_loss: 0.000000), lr: 0.00039888312724371757\n",
      "step: 200, acc: 0.945, loss: 0.189 (data_loss: 0.189, reg_loss: 0.000000), lr: 0.0003835826620636747\n",
      "step: 300, acc: 0.898, loss: 0.241 (data_loss: 0.241, reg_loss: 0.000000), lr: 0.0003694126339120798\n",
      "step: 400, acc: 0.891, loss: 0.325 (data_loss: 0.325, reg_loss: 0.000000), lr: 0.0003562522265764161\n",
      "step: 468, acc: 0.927, loss: 0.234 (data_loss: 0.234, reg_loss: 0.000000), lr: 0.00034782608695652176\n",
      "epoch: 5\n",
      "step: 0, acc: 0.891, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000000), lr: 0.0003477051460361613\n",
      "step: 100, acc: 0.859, loss: 0.394 (data_loss: 0.394, reg_loss: 0.000000), lr: 0.00033602150537634406\n",
      "step: 200, acc: 0.930, loss: 0.177 (data_loss: 0.177, reg_loss: 0.000000), lr: 0.00032509752925877764\n",
      "step: 300, acc: 0.914, loss: 0.232 (data_loss: 0.232, reg_loss: 0.000000), lr: 0.00031486146095717883\n",
      "step: 400, acc: 0.898, loss: 0.317 (data_loss: 0.317, reg_loss: 0.000000), lr: 0.00030525030525030525\n",
      "step: 468, acc: 0.938, loss: 0.209 (data_loss: 0.209, reg_loss: 0.000000), lr: 0.0002990430622009569\n",
      "epoch: 6\n",
      "step: 0, acc: 0.891, loss: 0.327 (data_loss: 0.327, reg_loss: 0.000000), lr: 0.0002989536621823617\n",
      "step: 100, acc: 0.867, loss: 0.381 (data_loss: 0.381, reg_loss: 0.000000), lr: 0.00029027576197387516\n",
      "step: 200, acc: 0.938, loss: 0.170 (data_loss: 0.170, reg_loss: 0.000000), lr: 0.0002820874471086037\n",
      "step: 300, acc: 0.922, loss: 0.222 (data_loss: 0.222, reg_loss: 0.000000), lr: 0.00027434842249657066\n",
      "step: 400, acc: 0.891, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000000), lr: 0.000267022696929239\n",
      "step: 468, acc: 0.938, loss: 0.194 (data_loss: 0.194, reg_loss: 0.000000), lr: 0.00026226068712300026\n",
      "epoch: 7\n",
      "step: 0, acc: 0.898, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000000), lr: 0.00026219192448872575\n",
      "step: 100, acc: 0.867, loss: 0.368 (data_loss: 0.368, reg_loss: 0.000000), lr: 0.00025549310168625444\n",
      "step: 200, acc: 0.953, loss: 0.164 (data_loss: 0.164, reg_loss: 0.000000), lr: 0.00024912805181863477\n",
      "step: 300, acc: 0.922, loss: 0.216 (data_loss: 0.216, reg_loss: 0.000000), lr: 0.0002430724355858046\n",
      "step: 400, acc: 0.891, loss: 0.290 (data_loss: 0.290, reg_loss: 0.000000), lr: 0.00023730422401518745\n",
      "step: 468, acc: 0.948, loss: 0.186 (data_loss: 0.186, reg_loss: 0.000000), lr: 0.00023353573096683791\n",
      "epoch: 8\n",
      "step: 0, acc: 0.906, loss: 0.283 (data_loss: 0.283, reg_loss: 0.000000), lr: 0.00023348120476301658\n",
      "step: 100, acc: 0.867, loss: 0.358 (data_loss: 0.358, reg_loss: 0.000000), lr: 0.00022815423226100847\n",
      "step: 200, acc: 0.938, loss: 0.162 (data_loss: 0.162, reg_loss: 0.000000), lr: 0.0002230649118893598\n",
      "step: 300, acc: 0.922, loss: 0.209 (data_loss: 0.209, reg_loss: 0.000000), lr: 0.00021819768710451667\n",
      "step: 400, acc: 0.891, loss: 0.277 (data_loss: 0.277, reg_loss: 0.000000), lr: 0.00021353833013025838\n",
      "step: 468, acc: 0.948, loss: 0.178 (data_loss: 0.178, reg_loss: 0.000000), lr: 0.00021048200378867611\n",
      "epoch: 9\n",
      "step: 0, acc: 0.914, loss: 0.268 (data_loss: 0.268, reg_loss: 0.000000), lr: 0.0002104377104377104\n",
      "step: 100, acc: 0.875, loss: 0.346 (data_loss: 0.346, reg_loss: 0.000000), lr: 0.0002061005770816158\n",
      "step: 200, acc: 0.945, loss: 0.158 (data_loss: 0.158, reg_loss: 0.000000), lr: 0.00020193861066235866\n",
      "step: 300, acc: 0.922, loss: 0.203 (data_loss: 0.203, reg_loss: 0.000000), lr: 0.0001979414093428345\n",
      "step: 400, acc: 0.898, loss: 0.269 (data_loss: 0.269, reg_loss: 0.000000), lr: 0.0001940993788819876\n",
      "step: 468, acc: 0.948, loss: 0.171 (data_loss: 0.171, reg_loss: 0.000000), lr: 0.00019157088122605365\n",
      "epoch: 10\n",
      "step: 0, acc: 0.930, loss: 0.256 (data_loss: 0.256, reg_loss: 0.000000), lr: 0.0001915341888527102\n",
      "step: 100, acc: 0.875, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000000), lr: 0.00018793459875963167\n",
      "step: 200, acc: 0.945, loss: 0.155 (data_loss: 0.155, reg_loss: 0.000000), lr: 0.00018446781036709093\n",
      "step: 300, acc: 0.930, loss: 0.198 (data_loss: 0.198, reg_loss: 0.000000), lr: 0.00018112660749864155\n",
      "step: 400, acc: 0.906, loss: 0.259 (data_loss: 0.259, reg_loss: 0.000000), lr: 0.00017790428749332856\n",
      "step: 468, acc: 0.948, loss: 0.166 (data_loss: 0.166, reg_loss: 0.000000), lr: 0.00017577781683951485\n",
      "training, acc: 0.915, loss: 0.237 (data_loss: 0.237, reg_loss: 0.000000), lr: 0.00017577781683951485\n",
      "Validation, acc: 0.879, loss: 0.337\n"
     ]
    }
   ],
   "source": [
    "#instantiate the model\n",
    "model = nnfs_module.Model()\n",
    "\n",
    "#add layers\n",
    "model.add(nnfs_module.Layer_Dense(X.shape[1], 128)) #dense layer 1 with 128 neurons\n",
    "model.add(nnfs_module.ReLU_Activation()) #ReLU used for activation\n",
    "model.add(nnfs_module.Layer_Dense(128,128)) #dense layer 2 with 128 neurons\n",
    "model.add(nnfs_module.ReLU_Activation())\n",
    "model.add(nnfs_module.Layer_Dense(128,10)) #dense layer 3 with 10 neurons\n",
    "model.add(nnfs_module.Activation_Softmax()) #output layer using Softmax for categorical classification\n",
    "\n",
    "#set loss, optimizer and accuracy objects\n",
    "model.set(\\\n",
    "         loss=nnfs_module.Loss_CategoricalCrossEntropy(),\\\n",
    "         optimizer=nnfs_module.Optimizer_Adam(decay=1e-3),\\\n",
    "         accuracy=nnfs_module.Accuracy_Categorical())\n",
    "\n",
    "#finalize the model\n",
    "model.finalize()\n",
    "\n",
    "#train the model\n",
    "model.train(X, y, validation_data=(X_test, y_test),\\\n",
    "           epochs=10, batch_size=128, print_every=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15f0070f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation, acc: 0.879, loss: 0.337\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ac0db",
   "metadata": {},
   "source": [
    "## Model training with parameter copying functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b30d3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1\n",
      "step: 0, acc: 0.070, loss: 2.848 (data_loss: 2.848, reg_loss: 0.000000), lr: 0.001\n",
      "step: 100, acc: 0.758, loss: 0.571 (data_loss: 0.571, reg_loss: 0.000000), lr: 0.0009090909090909091\n",
      "step: 200, acc: 0.891, loss: 0.336 (data_loss: 0.336, reg_loss: 0.000000), lr: 0.0008333333333333334\n",
      "step: 300, acc: 0.852, loss: 0.444 (data_loss: 0.444, reg_loss: 0.000000), lr: 0.0007692307692307692\n",
      "step: 400, acc: 0.844, loss: 0.506 (data_loss: 0.506, reg_loss: 0.000000), lr: 0.0007142857142857143\n",
      "step: 468, acc: 0.885, loss: 0.404 (data_loss: 0.404, reg_loss: 0.000000), lr: 0.000681198910081744\n",
      "epoch: 2\n",
      "step: 0, acc: 0.852, loss: 0.454 (data_loss: 0.454, reg_loss: 0.000000), lr: 0.0006807351940095304\n",
      "step: 100, acc: 0.828, loss: 0.457 (data_loss: 0.457, reg_loss: 0.000000), lr: 0.0006373486297004461\n",
      "step: 200, acc: 0.930, loss: 0.239 (data_loss: 0.239, reg_loss: 0.000000), lr: 0.0005991611743559018\n",
      "step: 300, acc: 0.875, loss: 0.343 (data_loss: 0.343, reg_loss: 0.000000), lr: 0.0005652911249293386\n",
      "step: 400, acc: 0.859, loss: 0.406 (data_loss: 0.406, reg_loss: 0.000000), lr: 0.0005350454788657037\n",
      "step: 468, acc: 0.885, loss: 0.322 (data_loss: 0.322, reg_loss: 0.000000), lr: 0.0005162622612287042\n",
      "epoch: 3\n",
      "step: 0, acc: 0.883, loss: 0.387 (data_loss: 0.387, reg_loss: 0.000000), lr: 0.0005159958720330237\n",
      "step: 100, acc: 0.867, loss: 0.405 (data_loss: 0.405, reg_loss: 0.000000), lr: 0.0004906771344455348\n",
      "step: 200, acc: 0.914, loss: 0.201 (data_loss: 0.201, reg_loss: 0.000000), lr: 0.0004677268475210477\n",
      "step: 300, acc: 0.898, loss: 0.281 (data_loss: 0.281, reg_loss: 0.000000), lr: 0.00044682752457551384\n",
      "step: 400, acc: 0.898, loss: 0.359 (data_loss: 0.359, reg_loss: 0.000000), lr: 0.00042771599657827206\n",
      "step: 468, acc: 0.917, loss: 0.271 (data_loss: 0.271, reg_loss: 0.000000), lr: 0.0004156275976724854\n",
      "epoch: 4\n",
      "step: 0, acc: 0.891, loss: 0.362 (data_loss: 0.362, reg_loss: 0.000000), lr: 0.0004154549231408392\n",
      "step: 100, acc: 0.867, loss: 0.374 (data_loss: 0.374, reg_loss: 0.000000), lr: 0.00039888312724371757\n",
      "step: 200, acc: 0.930, loss: 0.185 (data_loss: 0.185, reg_loss: 0.000000), lr: 0.0003835826620636747\n",
      "step: 300, acc: 0.898, loss: 0.262 (data_loss: 0.262, reg_loss: 0.000000), lr: 0.0003694126339120798\n",
      "step: 400, acc: 0.898, loss: 0.333 (data_loss: 0.333, reg_loss: 0.000000), lr: 0.0003562522265764161\n",
      "step: 468, acc: 0.917, loss: 0.236 (data_loss: 0.236, reg_loss: 0.000000), lr: 0.00034782608695652176\n",
      "epoch: 5\n",
      "step: 0, acc: 0.891, loss: 0.342 (data_loss: 0.342, reg_loss: 0.000000), lr: 0.0003477051460361613\n",
      "step: 100, acc: 0.875, loss: 0.366 (data_loss: 0.366, reg_loss: 0.000000), lr: 0.00033602150537634406\n",
      "step: 200, acc: 0.930, loss: 0.174 (data_loss: 0.174, reg_loss: 0.000000), lr: 0.00032509752925877764\n",
      "step: 300, acc: 0.898, loss: 0.251 (data_loss: 0.251, reg_loss: 0.000000), lr: 0.00031486146095717883\n",
      "step: 400, acc: 0.906, loss: 0.314 (data_loss: 0.314, reg_loss: 0.000000), lr: 0.00030525030525030525\n",
      "step: 468, acc: 0.938, loss: 0.214 (data_loss: 0.214, reg_loss: 0.000000), lr: 0.0002990430622009569\n",
      "epoch: 6\n",
      "step: 0, acc: 0.891, loss: 0.326 (data_loss: 0.326, reg_loss: 0.000000), lr: 0.0002989536621823617\n",
      "step: 100, acc: 0.891, loss: 0.348 (data_loss: 0.348, reg_loss: 0.000000), lr: 0.00029027576197387516\n",
      "step: 200, acc: 0.930, loss: 0.170 (data_loss: 0.170, reg_loss: 0.000000), lr: 0.0002820874471086037\n",
      "step: 300, acc: 0.906, loss: 0.240 (data_loss: 0.240, reg_loss: 0.000000), lr: 0.00027434842249657066\n",
      "step: 400, acc: 0.898, loss: 0.302 (data_loss: 0.302, reg_loss: 0.000000), lr: 0.000267022696929239\n",
      "step: 468, acc: 0.938, loss: 0.194 (data_loss: 0.194, reg_loss: 0.000000), lr: 0.00026226068712300026\n",
      "epoch: 7\n",
      "step: 0, acc: 0.898, loss: 0.312 (data_loss: 0.312, reg_loss: 0.000000), lr: 0.00026219192448872575\n",
      "step: 100, acc: 0.891, loss: 0.335 (data_loss: 0.335, reg_loss: 0.000000), lr: 0.00025549310168625444\n",
      "step: 200, acc: 0.938, loss: 0.168 (data_loss: 0.168, reg_loss: 0.000000), lr: 0.00024912805181863477\n",
      "step: 300, acc: 0.914, loss: 0.231 (data_loss: 0.231, reg_loss: 0.000000), lr: 0.0002430724355858046\n",
      "step: 400, acc: 0.898, loss: 0.293 (data_loss: 0.293, reg_loss: 0.000000), lr: 0.00023730422401518745\n",
      "step: 468, acc: 0.938, loss: 0.180 (data_loss: 0.180, reg_loss: 0.000000), lr: 0.00023353573096683791\n",
      "epoch: 8\n",
      "step: 0, acc: 0.898, loss: 0.299 (data_loss: 0.299, reg_loss: 0.000000), lr: 0.00023348120476301658\n",
      "step: 100, acc: 0.891, loss: 0.321 (data_loss: 0.321, reg_loss: 0.000000), lr: 0.00022815423226100847\n",
      "step: 200, acc: 0.938, loss: 0.165 (data_loss: 0.165, reg_loss: 0.000000), lr: 0.0002230649118893598\n",
      "step: 300, acc: 0.914, loss: 0.229 (data_loss: 0.229, reg_loss: 0.000000), lr: 0.00021819768710451667\n",
      "step: 400, acc: 0.906, loss: 0.282 (data_loss: 0.282, reg_loss: 0.000000), lr: 0.00021353833013025838\n",
      "step: 468, acc: 0.938, loss: 0.171 (data_loss: 0.171, reg_loss: 0.000000), lr: 0.00021048200378867611\n",
      "epoch: 9\n",
      "step: 0, acc: 0.922, loss: 0.289 (data_loss: 0.289, reg_loss: 0.000000), lr: 0.0002104377104377104\n",
      "step: 100, acc: 0.891, loss: 0.309 (data_loss: 0.309, reg_loss: 0.000000), lr: 0.0002061005770816158\n",
      "step: 200, acc: 0.930, loss: 0.164 (data_loss: 0.164, reg_loss: 0.000000), lr: 0.00020193861066235866\n",
      "step: 300, acc: 0.914, loss: 0.225 (data_loss: 0.225, reg_loss: 0.000000), lr: 0.0001979414093428345\n",
      "step: 400, acc: 0.906, loss: 0.273 (data_loss: 0.273, reg_loss: 0.000000), lr: 0.0001940993788819876\n",
      "step: 468, acc: 0.938, loss: 0.160 (data_loss: 0.160, reg_loss: 0.000000), lr: 0.00019157088122605365\n",
      "epoch: 10\n",
      "step: 0, acc: 0.914, loss: 0.280 (data_loss: 0.280, reg_loss: 0.000000), lr: 0.0001915341888527102\n",
      "step: 100, acc: 0.898, loss: 0.300 (data_loss: 0.300, reg_loss: 0.000000), lr: 0.00018793459875963167\n",
      "step: 200, acc: 0.930, loss: 0.161 (data_loss: 0.161, reg_loss: 0.000000), lr: 0.00018446781036709093\n",
      "step: 300, acc: 0.922, loss: 0.220 (data_loss: 0.220, reg_loss: 0.000000), lr: 0.00018112660749864155\n",
      "step: 400, acc: 0.914, loss: 0.262 (data_loss: 0.262, reg_loss: 0.000000), lr: 0.00017790428749332856\n",
      "step: 468, acc: 0.938, loss: 0.150 (data_loss: 0.150, reg_loss: 0.000000), lr: 0.00017577781683951485\n",
      "training, acc: 0.914, loss: 0.239 (data_loss: 0.239, reg_loss: 0.000000), lr: 0.00017577781683951485\n",
      "Validation, acc: 0.880, loss: 0.340\n",
      "Validation, acc: 0.880, loss: 0.340\n"
     ]
    }
   ],
   "source": [
    "#instantiate the model\n",
    "model = nnfs_module.Model()\n",
    "\n",
    "#add layers\n",
    "model.add(nnfs_module.Layer_Dense(X.shape[1], 128)) #dense layer 1 with 128 neurons\n",
    "model.add(nnfs_module.ReLU_Activation()) #ReLU used for activation\n",
    "model.add(nnfs_module.Layer_Dense(128,128)) #dense layer 2 with 128 neurons\n",
    "model.add(nnfs_module.ReLU_Activation())\n",
    "model.add(nnfs_module.Layer_Dense(128,10)) #dense layer 3 with 10 neurons\n",
    "model.add(nnfs_module.Activation_Softmax()) #output layer using Softmax for categorical classification\n",
    "\n",
    "#set loss, optimizer and accuracy objects\n",
    "model.set(\\\n",
    "         loss=nnfs_module.Loss_CategoricalCrossEntropy(),\\\n",
    "         optimizer=nnfs_module.Optimizer_Adam(decay=1e-3),\\\n",
    "         accuracy=nnfs_module.Accuracy_Categorical())\n",
    "\n",
    "#finalize the model\n",
    "model.finalize()\n",
    "\n",
    "#train the model\n",
    "model.train(X, y, validation_data=(X_test, y_test),\\\n",
    "           epochs=10, batch_size=128, print_every=100)\n",
    "\n",
    "parameters = model.get_parameters()\n",
    "\n",
    "#New model\n",
    "#instantiate the model\n",
    "model = nnfs_module.Model()\n",
    "\n",
    "#add layers\n",
    "model.add(nnfs_module.Layer_Dense(X.shape[1], 128)) #dense layer 1 with 128 neurons\n",
    "model.add(nnfs_module.ReLU_Activation()) #ReLU used for activation\n",
    "model.add(nnfs_module.Layer_Dense(128,128)) #dense layer 2 with 128 neurons\n",
    "model.add(nnfs_module.ReLU_Activation())\n",
    "model.add(nnfs_module.Layer_Dense(128,10)) #dense layer 3 with 10 neurons\n",
    "model.add(nnfs_module.Activation_Softmax()) #output layer using Softmax for categorical classification\n",
    "\n",
    "#set loss, optimizer and accuracy objects\n",
    "model.set(\\\n",
    "         loss=nnfs_module.Loss_CategoricalCrossEntropy(),\\\n",
    "         accuracy=nnfs_module.Accuracy_Categorical())\n",
    "\n",
    "#finalize the model\n",
    "model.finalize()\n",
    "\n",
    "#set model with parameter instead of training it\n",
    "model.set_parameters(parameters)\n",
    "\n",
    "#evaluate the model\n",
    "model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
